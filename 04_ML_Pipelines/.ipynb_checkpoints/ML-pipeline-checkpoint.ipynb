{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import mlflow\n",
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '292890d4-aa6d-4d5e-a085-97c80db3c30a'\n",
    "resource_group = 'MLOpsRG'\n",
    "workspace_name = 'MLOpsWS'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = workspace.get_mlflow_tracking_uri()\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://australiaeast.api.azureml.ms/mlflow/v1.0/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.MachineLearningServices/workspaces/MLOpsWS?\n"
     ]
    }
   ],
   "source": [
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_weather_data_portofTurku 1\n"
     ]
    }
   ],
   "source": [
    "# Importing pre-processed dataset\n",
    "dataset = Dataset.get_by_name(workspace, name='processed_weather_data_portofTurku')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 02:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 03:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 04:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 05:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 06:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.822222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0 2006-04-01 02:00:00  Port of Turku, Finland       8.755556      0.83   \n",
       "1 2006-04-01 03:00:00  Port of Turku, Finland       9.222222      0.85   \n",
       "2 2006-04-01 04:00:00  Port of Turku, Finland       7.733333      0.95   \n",
       "3 2006-04-01 05:00:00  Port of Turku, Finland       8.772222      0.89   \n",
       "4 2006-04-01 06:00:00  Port of Turku, Finland      10.822222      0.82   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          11.0446                   259        15.8263             1016.51   \n",
       "1          13.9587                   258        14.9569             1016.66   \n",
       "2          12.3648                   259         9.9820             1016.72   \n",
       "3          14.1519                   260         9.9820             1016.84   \n",
       "4          11.3183                   259         9.9820             1017.37   \n",
       "\n",
       "   Current_weather_condition  Future_weather_condition  \n",
       "0                          1                         1  \n",
       "1                          1                         1  \n",
       "2                          1                         1  \n",
       "3                          1                         1  \n",
       "4                          1                         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Pre-Processed data into Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set is used later to evaluate model performance post training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.iloc[:77160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df.drop(df_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19289, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Training and Validation data to the datastore on the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('Data/training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv('Data/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to data\n",
      "Uploading an estimated of 2 files\n",
      "Uploading Data/validation_data.csv\n",
      "Uploaded Data/validation_data.csv, 1 files out of an estimated total of 2\n",
      "Uploading Data/training_data.csv\n",
      "Uploaded Data/training_data.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/data')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deprecated\n",
    "# datastore.upload(src_dir='Data', target_path='data')\n",
    "\n",
    "# from azureml.core import Dataset\n",
    "# https://azure.github.io/azureml-cheatsheets/docs/cheatsheets/python/v1/data/\n",
    "Dataset.File.upload_directory(src_dir=\"Data\", target=(datastore, \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Dataset.Tabular.from_delimited_files(datastore.path('data/training_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset.Tabular.from_delimited_files(datastore.path('data/validation_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = training_dataset.register(workspace=workspace,\n",
    "                                 name='training_dataset',\n",
    "                                 description='Dataset to use for ML training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = validation_dataset.register(workspace=workspace,\n",
    "                                 name='validation_dataset',\n",
    "                                 description='Dataset for validation ML models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset 1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='training_dataset')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 02:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 03:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 04:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 05:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 06:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.822222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0 2006-04-01 02:00:00  Port of Turku, Finland       8.755556      0.83   \n",
       "1 2006-04-01 03:00:00  Port of Turku, Finland       9.222222      0.85   \n",
       "2 2006-04-01 04:00:00  Port of Turku, Finland       7.733333      0.95   \n",
       "3 2006-04-01 05:00:00  Port of Turku, Finland       8.772222      0.89   \n",
       "4 2006-04-01 06:00:00  Port of Turku, Finland      10.822222      0.82   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          11.0446                   259        15.8263             1016.51   \n",
       "1          13.9587                   258        14.9569             1016.66   \n",
       "2          12.3648                   259         9.9820             1016.72   \n",
       "3          14.1519                   260         9.9820             1016.84   \n",
       "4          11.3183                   259         9.9820             1017.37   \n",
       "\n",
       "   Current_weather_condition  Future_weather_condition  \n",
       "0                          1                         1  \n",
       "1                          1                         1  \n",
       "2                          1                         1  \n",
       "3                          1                         1  \n",
       "4                          1                         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars', 'Current_weather_condition']].values\n",
    "y = df['Future_weather_condition'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Testing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/10 10:08:05 INFO mlflow.tracking.fluent: Experiment with name 'mlflow-support-vector-machine' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', experiment_id='2c836679-a501-4918-bb7d-5ae0055e2f78', lifecycle_stage='active', name='mlflow-support-vector-machine', tags={}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO MAHTAB - Did not understand why we need AzureML run and mlflow run both?\n",
    "# initialize a run in Azureml and mlflow experiments\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 52s, sys: 588 ms, total: 10min 52s\n",
      "Wall time: 10min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__break_ties': False,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'scale',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=svc_grid.get_params(deep=True)['estimator__C'], kernel=svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"C\", svc_grid.get_params(deep=True)['estimator__C'])\n",
    "run.log(\"Kernel\", svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_svc, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8864428755463128\n"
     ]
    }
   ],
   "source": [
    "print(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to AzureML and MLflow\n",
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 1e6622ce-1534-4ef4-96b9-28f7cd63b63d\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset name': 'training_dataset',\n",
       " 'dataset Version': 1,\n",
       " 'C': 1.0,\n",
       " 'Kernel': 'rbf',\n",
       " 'Test_accuracy': 0.9519180922757906,\n",
       " 'Precision': 0.8869828453699851,\n",
       " 'Recall': 0.8859050416892464,\n",
       " 'F-Score': 0.8864428755463128,\n",
       " 'Git-sha': '80767a16437e8bace0463ae04d942313e1181754'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.MachineLearningServices/workspaces/MLOpsWS',\n",
       " 'name': 'MLOpsWS',\n",
       " 'identity': {'principal_id': '39d61691-35f1-4e0a-a314-1252d9cd877e',\n",
       "  'tenant_id': '03ff20ec-51f3-415c-9462-b61ddcf1ce16',\n",
       "  'type': 'SystemAssigned'},\n",
       " 'location': 'australiaeast',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'sku': 'Basic',\n",
       " 'workspaceid': '31f4ef02-a30d-4a01-993f-1fb82d100b21',\n",
       " 'sdkTelemetryAppInsightsKey': 'bd22fe07-ca7e-4337-bd98-3d5116261c1f',\n",
       " 'description': '',\n",
       " 'friendlyName': 'MLOpsWS',\n",
       " 'containerRegistry': '/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.ContainerRegistry/registries/mlopscr1010',\n",
       " 'keyVault': '/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.Keyvault/vaults/mlopskv1010',\n",
       " 'applicationInsights': '/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.insights/components/mlopsai1010',\n",
       " 'storageAccount': '/subscriptions/292890d4-aa6d-4d5e-a085-97c80db3c30a/resourceGroups/MLOpsRG/providers/Microsoft.Storage/storageAccounts/mlopssa1010',\n",
       " 'hbiWorkspace': False,\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'discoveryUrl': 'https://australiaeast.api.azureml.ms/discovery',\n",
       " 'notebookInfo': {'fqdn': 'ml-mlopsws-australiaeast-31f4ef02-a30d-4a01-993f-1fb82d100b21.australiaeast.notebooks.azure.net',\n",
       "  'resource_id': '28e6226779114f49b6a95387b6fd483f'},\n",
       " 'v1LegacyMode': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='outputs', flavors={'python_function': {'model_path': 'model.pkl', 'loader_module': 'mlflow.sklearn', 'python_version': '3.8.5', 'env': 'conda.yaml'}, 'sklearn': {'pickled_model': 'model.pkl', 'sklearn_version': '0.22.1', 'serialization_format': 'cloudpickle', 'code': None}}, model_uri='runs:/aa70964f-610d-4b42-9df7-2d17c02ae562/outputs', model_uuid='f898084a67af4cd284918ff519f16c60', run_id='aa70964f-610d-4b42-9df7-2d17c02ae562', saved_input_example_info=None, signature_dict=None, utc_time_created='2022-10-10 10:35:33.475480', mlflow_version='1.28.0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "mlflow.sklearn.log_model(svc, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added this to end the run; it was still running after previous statement\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', experiment_id='b65bcfdb-8b0a-49cb-b2f4-2a212edf68c4', lifecycle_stage='active', name='mlflow-random-forest-classifier', tags={}>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize runs in Azureml and mlflow\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "# mlflow.start_run(nested=True)\n",
    "\n",
    "\n",
    "# Log dataset used \n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.57 s, sys: 12 ms, total: 6.59 s\n",
      "Wall time: 6.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"max_depth\", 10)\n",
    "run.log(\"random_state\", 0)\n",
    "run.log(\"n_estimators\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_rf)\n",
    "fscore = f1_score(y_test, predicted_rf, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_rf, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_rf, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: c388a1e1-f9ba-4d84-b054-698440bb1265\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset name': 'training_dataset',\n",
       " 'dataset Version': 1,\n",
       " 'max_depth': 10,\n",
       " 'random_state': 0,\n",
       " 'n_estimators': 100,\n",
       " 'Test_accuracy': 0.9548989113530326,\n",
       " 'Precision': 0.9018705246237031,\n",
       " 'Recall': 0.8804084310202218,\n",
       " 'F-Score': 0.8907272822498857,\n",
       " 'Git-sha': '9f9c93443b9aa1cc9dbe29702e53b95f4059eab9'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle file or onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n"
     ]
    }
   ],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "# Convert into RF model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model support-vector-classifier\n",
      "Name: support-vector-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/svc.onnx', # this points to a local file \n",
    "                       model_name = \"support-vector-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9519'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Support vector classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model random-forest-classifier\n",
      "Name: random-forest-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf.onnx', # this points to a local file \n",
    "                       model_name = \"random-forest-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9548'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random forest classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='outputs/svc.onnx', flavors={'python_function': {'model_path': 'model.pkl', 'loader_module': 'mlflow.sklearn', 'python_version': '3.8.5', 'env': 'conda.yaml'}, 'sklearn': {'pickled_model': 'model.pkl', 'sklearn_version': '0.22.1', 'serialization_format': 'cloudpickle', 'code': None}}, model_uri='runs:/14b34d1f-68fa-4df5-a9f6-5129d05e100b/outputs/svc.onnx', model_uuid='54fda8271a80487bb07232ad1e007364', run_id='14b34d1f-68fa-4df5-a9f6-5129d05e100b', saved_input_example_info=None, signature_dict=None, utc_time_created='2022-10-10 01:46:44.569356', mlflow_version='1.28.0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(svc, 'outputs/svc.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='outputs/rf.onnx', flavors={'python_function': {'model_path': 'model.pkl', 'loader_module': 'mlflow.sklearn', 'python_version': '3.8.5', 'env': 'conda.yaml'}, 'sklearn': {'pickled_model': 'model.pkl', 'sklearn_version': '0.22.1', 'serialization_format': 'cloudpickle', 'code': None}}, model_uri='runs:/14b34d1f-68fa-4df5-a9f6-5129d05e100b/outputs/rf.onnx', model_uuid='db6fff382b974f698f75baec8709b7ca', run_id='14b34d1f-68fa-4df5-a9f6-5129d05e100b', saved_input_example_info=None, signature_dict=None, utc_time_created='2022-10-10 01:46:48.710966', mlflow_version='1.28.0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(rf, 'outputs/rf.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/scaler.pkl', 'wb') as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model scaler\n",
      "Name: scaler\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "scaler = Model.register(model_path = './outputs/scaler.pkl', # this points to a local file \n",
    "                       model_name = \"scaler\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Scaler used for scaling incoming inference data\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', scaler.name)\n",
    "print('Version:', scaler.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
